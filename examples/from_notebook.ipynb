{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea1e6eb",
   "metadata": {},
   "source": [
    "# Launching Multi-Node Training from a Jupyter Environment\n",
    "> Using the `notebook_launcher` to use Accelerate from inside a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d7904",
   "metadata": {},
   "source": [
    "## General Overview\n",
    "\n",
    "This notebook covers how to run the `cv_example.py` script as a Jupyter Notebook and train it on a distributed system. It will also cover the few specific requirements needed for ensuring your environment is configured properly, your data has been prepared properly, and finally how to launch training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dafb31",
   "metadata": {},
   "source": [
    "## Configuring the Environment\n",
    "\n",
    "Before any training can be performed, an accelerate config file must exist in the system. Usually this can be done by running the following in a terminal:\n",
    "\n",
    "```bash\n",
    "accelerate config\n",
    "```\n",
    "\n",
    "However, if general defaults are fine and you are *not* running on a TPU, accelerate has a utility to quickly write your GPU configuration into a config file via `write_basic_config`.\n",
    "\n",
    "> Note: The following cell will restart Jupyter after writing the configuration, as CUDA code was called to perform this. More information on why that is important will be discussed later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae835e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from accelerate.utils import write_basic_config\n",
    "#write_basic_config() # Write a config file\n",
    "#os._exit(00) # Restart the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e067d11a",
   "metadata": {},
   "source": [
    "## Preparing the Dataset and Model\n",
    "\n",
    "Next you should prepare your dataset. As hinted at earlier, great care should be taken when preparing the `DataLoaders` and model to make sure that **nothing** is put on *any* GPU. Nor should any CUDA memory be initialized or ran.\n",
    "\n",
    "More specifically, nothing should be ran that stems from `torch.cuda`. The `notebook_launcher` requires this to be the case.\n",
    "\n",
    "If you do, it is recommended to put that specific code into a function and call that from within the notebook launcher interface, which will be shown later. \n",
    "\n",
    "Make sure the dataset is downloaded based on the directions [here](https://github.com/huggingface/accelerate/tree/main/examples#simple-vision-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4805cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, torch, PIL\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, Resize, ToTensor\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938f8e4",
   "metadata": {},
   "source": [
    "First we'll create a function to extract the class name based on a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd4907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beagle_32.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = \"../../images\"\n",
    "fnames = os.listdir(data_dir)\n",
    "fname = fnames[0]\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39caa398",
   "metadata": {},
   "source": [
    "In the case here, the label is `beagle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e28d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_label(fname):\n",
    "    stem = fname.split(os.path.sep)[-1]\n",
    "    return re.search(r\"^(.*)_\\d+\\.jpg$\", stem).groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab40fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beagle'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_label(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6a733",
   "metadata": {},
   "source": [
    "Next we'll create a `Dataset` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72242e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetsDataset(Dataset):\n",
    "    def __init__(self, file_names, image_transform=None, label_to_id=None):\n",
    "        self.file_names = file_names\n",
    "        self.image_transform = image_transform\n",
    "        self.label_to_id = label_to_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.file_names[idx]\n",
    "        raw_image = PIL.Image.open(fname)\n",
    "        image = raw_image.convert(\"RGB\")\n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform(image)\n",
    "        label = extract_label(fname)\n",
    "        if self.label_to_id is not None:\n",
    "            label = self.label_to_id[label]\n",
    "        return {\"image\": image, \"label\": label}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222fc93a",
   "metadata": {},
   "source": [
    "And build our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0f2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the image filenames\n",
    "fnames = [\n",
    "    os.path.join(\"../../images\", fname)\n",
    "    for fname in fnames\n",
    "    if fname.endswith(\".jpg\")\n",
    "]\n",
    "\n",
    "# Build the labels\n",
    "all_labels = [\n",
    "    extract_label(fname)\n",
    "    for fname in fnames\n",
    "]\n",
    "id_to_label = list(set(all_labels))\n",
    "id_to_label.sort()\n",
    "label_to_id = {lbl: i for i, lbl in enumerate(id_to_label)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e66fd",
   "metadata": {},
   "source": [
    "> Note: This will be stored inside of a function as we'll be setting our seed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25430a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size:int=64):\n",
    "    \"Builds a set of dataloaders with a batch_size\"\n",
    "    random_perm = np.random.permutation(len(fnames))\n",
    "    cut = int(0.8 * len(fnames))\n",
    "    train_split = random_perm[:cut]\n",
    "    eval_split = random_perm[:cut]\n",
    "    \n",
    "    # For training we use a simple RandomResizedCrop\n",
    "    train_tfm = Compose([\n",
    "        RandomResizedCrop((224, 224), scale=(0.5, 1.0)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    train_dataset = PetsDataset(\n",
    "        [fnames[i] for i in train_split],\n",
    "        image_transform=train_tfm,\n",
    "        label_to_id=label_to_id\n",
    "    )\n",
    "    \n",
    "    # For evaluation we use a deterministic Resize\n",
    "    eval_tfm = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    eval_dataset = PetsDataset(\n",
    "        [fnames[i] for i in eval_split],\n",
    "        image_transform=eval_tfm,\n",
    "        label_to_id=label_to_id\n",
    "    )\n",
    "    \n",
    "    # Instantiate dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        shuffle=True, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size*2,\n",
    "        num_workers=4\n",
    "    )\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91084504",
   "metadata": {},
   "source": [
    "## Writing the Training Function\n",
    "\n",
    "Now we can build our training loop. `notebook_launcher` works by passing in a function to call that will be ran across the distributed system.\n",
    "\n",
    "Here is a basic training loop for our animal classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4366f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(mixed_precision=\"fp16\", seed:int=42, batch_size:int=64):\n",
    "    set_seed(seed)\n",
    "    # Initialize accelerator\n",
    "    accelerator = Accelerator(mixed_precision=mixed_precision)\n",
    "    # Build dataloaders\n",
    "    train_dataloader, eval_dataloader = get_dataloaders(batch_size)\n",
    "    \n",
    "    # instantiate the model (we build the model here so that the seed also controls new weight initaliziations)\n",
    "    model = create_model(\"resnet50d\", pretrained=True, num_classes=len(label_to_id))\n",
    "    \n",
    "    # Freeze the base model\n",
    "    for param in model.parameters(): \n",
    "        param.requires_grad=False\n",
    "    for param in model.get_classifier().parameters():\n",
    "        param.requires_grad=True\n",
    "        \n",
    "    # We normalize the batches of images to be a bit faster\n",
    "    mean = torch.tensor(model.default_cfg[\"mean\"])[None, :, None, None]\n",
    "    std = torch.tensor(model.default_cfg[\"std\"])[None, :, None, None]\n",
    "    \n",
    "    # To make this constant available on the active device, we set it to the accelerator device\n",
    "    mean = mean.to(accelerator.device)\n",
    "    std = std.to(accelerator.device)\n",
    "    \n",
    "    # Intantiate the optimizer\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr = 3e-2/25)\n",
    "    \n",
    "    # Instantiate the learning rate scheduler\n",
    "    lr_scheduler = OneCycleLR(\n",
    "        optimizer=optimizer, \n",
    "        max_lr=3e-2, \n",
    "        epochs=1, \n",
    "        steps_per_epoch=len(train_dataloader)\n",
    "    )\n",
    "    \n",
    "    # Prepare everything\n",
    "    # There is no specific order to remember, we just need to unpack the objects in the same order we gave them to the\n",
    "    # prepare method.\n",
    "    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    "    )\n",
    "    lr_scheduler._i = 0\n",
    "    accelerator.print(f\"LR Scheduler num_batches: {lr_scheduler.scheduler.total_steps}\")\n",
    "    \n",
    "    # Now we train the model\n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # We could avoid this line since we set the accelerator with `device_placement=True`.\n",
    "            batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n",
    "            inputs = (batch[\"image\"] - mean) / std\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, batch[\"label\"])\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        accurate = 0\n",
    "        num_elems = 0\n",
    "        for _, batch in enumerate(eval_dataloader):\n",
    "            # We could avoid this line since we set the accelerator with `device_placement=True`.\n",
    "            batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n",
    "            inputs = (batch[\"image\"] - mean) / std\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            predictions = outputs.argmax(dim=-1)\n",
    "            accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch[\"label\"])\n",
    "            num_elems += accurate_preds.shape[0]\n",
    "            accurate += accurate_preds.long().sum()\n",
    "\n",
    "        eval_metric = accurate.item() / num_elems\n",
    "        # Use accelerator.print to print only on the main process.\n",
    "        accelerator.print(f\"epoch {epoch}: {100 * eval_metric:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a7f5f",
   "metadata": {},
   "source": [
    "All that's left is to use the `notebook_launcher`.\n",
    "\n",
    "We pass in the function, the arguments (as a tuple), and the number of processes to train on. (See the [documentation](https://huggingface.co/docs/accelerate/launcher) for more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a096cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e577515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import patch\n",
    "from accelerate.scheduler import AcceleratedScheduler, AcceleratorState\n",
    "\n",
    "@patch\n",
    "def step(self:AcceleratedScheduler, *args, **kwargs):\n",
    "    if not self.step_with_optimizer:\n",
    "        # No link between scheduler and optimizer -> just step\n",
    "        self.scheduler.step(*args, **kwargs)\n",
    "        return\n",
    "\n",
    "    # Otherwise, first make sure the optimizer was stepped.\n",
    "    for opt in self.optimizers:\n",
    "        if opt.step_was_skipped:\n",
    "            return\n",
    "\n",
    "    if self.split_batches:\n",
    "        # Split batches -> the training dataloader batch size is not changed so one step per training step\n",
    "        self.scheduler.step(*args, **kwargs)\n",
    "    else:\n",
    "        # Otherwise the training dataloader batch size was multiplied by `num_processes`, so we need to do\n",
    "        # num_processes steps per training step\n",
    "        num_processes = AcceleratorState().num_processes\n",
    "        if AcceleratorState().process_index == 0:\n",
    "            print(f'_i before step: {self._i}')\n",
    "        for _ in range(num_processes):\n",
    "            self._i += 1\n",
    "            if AcceleratorState().process_index == 0:\n",
    "                print(f'_i after step: {self._i}')\n",
    "            self.scheduler.step(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0586104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n",
      "LR Scheduler num_batches: 93\n",
      "_i before step: 0\n",
      "_i after step: 1\n",
      "_i before step: 1\n",
      "_i after step: 2\n",
      "_i before step: 2\n",
      "_i after step: 3\n",
      "_i before step: 3\n",
      "_i after step: 4\n",
      "_i before step: 4\n",
      "_i after step: 5\n",
      "_i before step: 5\n",
      "_i after step: 6\n",
      "_i before step: 6\n",
      "_i after step: 7\n",
      "_i before step: 7\n",
      "_i after step: 8\n",
      "_i before step: 8\n",
      "_i after step: 9\n",
      "_i before step: 9\n",
      "_i after step: 10\n",
      "_i before step: 10\n",
      "_i after step: 11\n",
      "_i before step: 11\n",
      "_i after step: 12\n",
      "_i before step: 12\n",
      "_i after step: 13\n",
      "_i before step: 13\n",
      "_i after step: 14\n",
      "_i before step: 14\n",
      "_i after step: 15\n",
      "_i before step: 15\n",
      "_i after step: 16\n",
      "_i before step: 16\n",
      "_i after step: 17\n",
      "_i before step: 17\n",
      "_i after step: 18\n",
      "_i before step: 18\n",
      "_i after step: 19\n",
      "_i before step: 19\n",
      "_i after step: 20\n",
      "_i before step: 20\n",
      "_i after step: 21\n",
      "_i before step: 21\n",
      "_i after step: 22\n",
      "_i before step: 22\n",
      "_i after step: 23\n",
      "_i before step: 23\n",
      "_i after step: 24\n",
      "_i before step: 24\n",
      "_i after step: 25\n",
      "_i before step: 25\n",
      "_i after step: 26\n",
      "_i before step: 26\n",
      "_i after step: 27\n",
      "_i before step: 27\n",
      "_i after step: 28\n",
      "_i before step: 28\n",
      "_i after step: 29\n",
      "_i before step: 29\n",
      "_i after step: 30\n",
      "_i before step: 30\n",
      "_i after step: 31\n",
      "_i before step: 31\n",
      "_i after step: 32\n",
      "_i before step: 32\n",
      "_i after step: 33\n",
      "_i before step: 33\n",
      "_i after step: 34\n",
      "_i before step: 34\n",
      "_i after step: 35\n",
      "_i before step: 35\n",
      "_i after step: 36\n",
      "_i before step: 36\n",
      "_i after step: 37\n",
      "_i before step: 37\n",
      "_i after step: 38\n",
      "_i before step: 38\n",
      "_i after step: 39\n",
      "_i before step: 39\n",
      "_i after step: 40\n",
      "_i before step: 40\n",
      "_i after step: 41\n",
      "_i before step: 41\n",
      "_i after step: 42\n",
      "_i before step: 42\n",
      "_i after step: 43\n",
      "_i before step: 43\n",
      "_i after step: 44\n",
      "_i before step: 44\n",
      "_i after step: 45\n",
      "_i before step: 45\n",
      "_i after step: 46\n",
      "_i before step: 46\n",
      "_i after step: 47\n",
      "_i before step: 47\n",
      "_i after step: 48\n",
      "_i before step: 48\n",
      "_i after step: 49\n",
      "_i before step: 49\n",
      "_i after step: 50\n",
      "_i before step: 50\n",
      "_i after step: 51\n",
      "_i before step: 51\n",
      "_i after step: 52\n",
      "_i before step: 52\n",
      "_i after step: 53\n",
      "_i before step: 53\n",
      "_i after step: 54\n",
      "_i before step: 54\n",
      "_i after step: 55\n",
      "_i before step: 55\n",
      "_i after step: 56\n",
      "_i before step: 56\n",
      "_i after step: 57\n",
      "_i before step: 57\n",
      "_i after step: 58\n",
      "_i before step: 58\n",
      "_i after step: 59\n",
      "_i before step: 59\n",
      "_i after step: 60\n",
      "_i before step: 60\n",
      "_i after step: 61\n",
      "_i before step: 61\n",
      "_i after step: 62\n",
      "_i before step: 62\n",
      "_i after step: 63\n",
      "_i before step: 63\n",
      "_i after step: 64\n",
      "_i before step: 64\n",
      "_i after step: 65\n",
      "_i before step: 65\n",
      "_i after step: 66\n",
      "_i before step: 66\n",
      "_i after step: 67\n",
      "_i before step: 67\n",
      "_i after step: 68\n",
      "_i before step: 68\n",
      "_i after step: 69\n",
      "_i before step: 69\n",
      "_i after step: 70\n",
      "_i before step: 70\n",
      "_i after step: 71\n",
      "_i before step: 71\n",
      "_i after step: 72\n",
      "_i before step: 72\n",
      "_i after step: 73\n",
      "_i before step: 73\n",
      "_i after step: 74\n",
      "_i before step: 74\n",
      "_i after step: 75\n",
      "_i before step: 75\n",
      "_i after step: 76\n",
      "_i before step: 76\n",
      "_i after step: 77\n",
      "_i before step: 77\n",
      "_i after step: 78\n",
      "_i before step: 78\n",
      "_i after step: 79\n",
      "_i before step: 79\n",
      "_i after step: 80\n",
      "_i before step: 80\n",
      "_i after step: 81\n",
      "_i before step: 81\n",
      "_i after step: 82\n",
      "_i before step: 82\n",
      "_i after step: 83\n",
      "_i before step: 83\n",
      "_i after step: 84\n",
      "_i before step: 84\n",
      "_i after step: 85\n",
      "_i before step: 85\n",
      "_i after step: 86\n",
      "_i before step: 86\n",
      "_i after step: 87\n",
      "_i before step: 87\n",
      "_i after step: 88\n",
      "_i before step: 88\n",
      "_i after step: 89\n",
      "_i before step: 89\n",
      "_i after step: 90\n",
      "_i before step: 90\n",
      "_i after step: 91\n",
      "_i before step: 91\n",
      "_i after step: 92\n",
      "_i before step: 92\n",
      "_i after step: 93\n",
      "epoch 0: 91.91\n"
     ]
    }
   ],
   "source": [
    "args = (\"fp16\", 42, 64)\n",
    "notebook_launcher(training_loop, args, num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756c971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n",
      "LR Scheduler num_batches: 93\n",
      "_i before step: 0\n",
      "_i after step: 1\n",
      "_i after step: 2\n",
      "_i before step: 2\n",
      "_i after step: 3\n",
      "_i after step: 4\n",
      "_i before step: 4\n",
      "_i after step: 5\n",
      "_i after step: 6\n",
      "_i before step: 6\n",
      "_i after step: 7\n",
      "_i after step: 8\n",
      "_i before step: 8\n",
      "_i after step: 9\n",
      "_i after step: 10\n",
      "_i before step: 10\n",
      "_i after step: 11\n",
      "_i after step: 12\n",
      "_i before step: 12\n",
      "_i after step: 13\n",
      "_i after step: 14\n",
      "_i before step: 14\n",
      "_i after step: 15\n",
      "_i after step: 16\n",
      "_i before step: 16\n",
      "_i after step: 17\n",
      "_i after step: 18\n",
      "_i before step: 18\n",
      "_i after step: 19\n",
      "_i after step: 20\n",
      "_i before step: 20\n",
      "_i after step: 21\n",
      "_i after step: 22\n",
      "_i before step: 22\n",
      "_i after step: 23\n",
      "_i after step: 24\n",
      "_i before step: 24\n",
      "_i after step: 25\n",
      "_i after step: 26\n",
      "_i before step: 26\n",
      "_i after step: 27\n",
      "_i after step: 28\n",
      "_i before step: 28\n",
      "_i after step: 29\n",
      "_i after step: 30\n",
      "_i before step: 30\n",
      "_i after step: 31\n",
      "_i after step: 32\n",
      "_i before step: 32\n",
      "_i after step: 33\n",
      "_i after step: 34\n",
      "_i before step: 34\n",
      "_i after step: 35\n",
      "_i after step: 36\n",
      "_i before step: 36\n",
      "_i after step: 37\n",
      "_i after step: 38\n",
      "_i before step: 38\n",
      "_i after step: 39\n",
      "_i after step: 40\n",
      "_i before step: 40\n",
      "_i after step: 41\n",
      "_i after step: 42\n",
      "_i before step: 42\n",
      "_i after step: 43\n",
      "_i after step: 44\n",
      "_i before step: 44\n",
      "_i after step: 45\n",
      "_i after step: 46\n",
      "_i before step: 46\n",
      "_i after step: 47\n",
      "_i after step: 48\n",
      "_i before step: 48\n",
      "_i after step: 49\n",
      "_i after step: 50\n",
      "_i before step: 50\n",
      "_i after step: 51\n",
      "_i after step: 52\n",
      "_i before step: 52\n",
      "_i after step: 53\n",
      "_i after step: 54\n",
      "_i before step: 54\n",
      "_i after step: 55\n",
      "_i after step: 56\n",
      "_i before step: 56\n",
      "_i after step: 57\n",
      "_i after step: 58\n",
      "_i before step: 58\n",
      "_i after step: 59\n",
      "_i after step: 60\n",
      "_i before step: 60\n",
      "_i after step: 61\n",
      "_i after step: 62\n",
      "_i before step: 62\n",
      "_i after step: 63\n",
      "_i after step: 64\n",
      "_i before step: 64\n",
      "_i after step: 65\n",
      "_i after step: 66\n",
      "_i before step: 66\n",
      "_i after step: 67\n",
      "_i after step: 68\n",
      "_i before step: 68\n",
      "_i after step: 69\n",
      "_i after step: 70\n",
      "_i before step: 70\n",
      "_i after step: 71\n",
      "_i after step: 72\n",
      "_i before step: 72\n",
      "_i after step: 73\n",
      "_i after step: 74\n",
      "_i before step: 74\n",
      "_i after step: 75\n",
      "_i after step: 76\n",
      "_i before step: 76\n",
      "_i after step: 77\n",
      "_i after step: 78\n",
      "_i before step: 78\n",
      "_i after step: 79\n",
      "_i after step: 80\n",
      "_i before step: 80\n",
      "_i after step: 81\n",
      "_i after step: 82\n",
      "_i before step: 82\n",
      "_i after step: 83\n",
      "_i after step: 84\n",
      "_i before step: 84\n",
      "_i after step: 85\n",
      "_i after step: 86\n",
      "_i before step: 86\n",
      "_i after step: 87\n",
      "_i after step: 88\n",
      "_i before step: 88\n",
      "_i after step: 89\n",
      "_i after step: 90\n",
      "_i before step: 90\n",
      "_i after step: 91\n",
      "_i after step: 92\n",
      "_i before step: 92\n",
      "_i after step: 93\n",
      "_i after step: 94\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\n    fn(i, *args)\n  File \"/home/zach_mueller_huggingface_co/accelerate/src/accelerate/utils/launch.py\", line 55, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_14356/3782442403.py\", line 57, in training_loop\n    lr_scheduler.step()\n  File \"/tmp/ipykernel_14356/2076112284.py\", line 29, in step\n    self.scheduler.step(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 152, in step\n    values = self.get_lr()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 1572, in get_lr\n    .format(step_num + 1, self.total_steps))\nValueError: Tried to step 95 times. The specified number of total steps is 93\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14356/567082043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"fp16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnotebook_launcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/accelerate/src/accelerate/launchers.py\u001b[0m in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, use_fp16, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Launching training on {num_processes} GPUs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fork\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n-- Process %d terminated with the following error:\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moriginal_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mProcessRaisedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\n    fn(i, *args)\n  File \"/home/zach_mueller_huggingface_co/accelerate/src/accelerate/utils/launch.py\", line 55, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_14356/3782442403.py\", line 57, in training_loop\n    lr_scheduler.step()\n  File \"/tmp/ipykernel_14356/2076112284.py\", line 29, in step\n    self.scheduler.step(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 152, in step\n    values = self.get_lr()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 1572, in get_lr\n    .format(step_num + 1, self.total_steps))\nValueError: Tried to step 95 times. The specified number of total steps is 93\n"
     ]
    }
   ],
   "source": [
    "# args = (\"fp16\", 42, 64)\n",
    "# notebook_launcher(training_loop, args, num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f497f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62fab197",
   "metadata": {},
   "source": [
    "And that's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c964a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook showed how to perform distributed training from inside of a Jupyter Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47662a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
