name: Self-hosted runner (scheduled)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 2 * * *"

env:
  RUN_SLOW: yes

jobs:
  run_all_tests_single_gpu:
    runs-on: [self-hosted, docker-gpu, multi-gpu]
    container:
      image: huggingface/accelerate-gpu:latest
      options: --gpus all --shm-size "16gb"
    defaults:
      run:
        working-directory: accelerate/
        shell: bash
    steps:
      - name: Run source
        run: |
          source ~/.profile
      - name: Print working directory
        run: |
          echo "$PWD"
      # - name: Clone and install
      #   run: |
      #     cd accelerate
      # - name: Are GPUs recognized by PyTorch
      #   run: |
      #     utils/print_env_pt.py
      - name: Run test on GPUs
        run: |
          CUDA_VISIBLE_DEVICES="0" make test

      - name: Run examples on GPUs
        run: |
          CUDA_VISIBLE_DEVICES="0" make test_examples

  run_all_tests_multi_gpu:
    runs-on: [self-hosted, docker-gpu, multi-gpu]
    container:
      image: huggingface/accelerate-gpu:latest
      options: --gpus all --shm-size "16gb"
    defaults:
      run:
        working-directory: accelerate/
        shell: bash
    steps:
      - name: Run source
        run: |
          source ~/.profile
      - name: Print working directory
        run: |
          echo "$PWD"
      # - name: Clone and install
      #   run: |
      #     cd accelerate
      # - name: Are GPUs recognized by PyTorch
      #   run: |
      #     utils/print_env_pt.py
      - name: Run test on GPUs
        run: |
          CUDA_VISIBLE_DEVICES="0,1" make test

      - name: Run examples on GPUs
        run: |
          CUDA_VISIBLE_DEVICES="0,1" make test_examples
