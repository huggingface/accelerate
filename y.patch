diff --git a/src/accelerate/accelerator.py b/src/accelerate/accelerator.py
index fecd441..58dfdd2 100755
--- a/src/accelerate/accelerator.py
+++ b/src/accelerate/accelerator.py
@@ -2388,8 +2388,10 @@ class Accelerator:
         if model is not None:
             megatron_lm_plugin.set_network_size_args(model, batch_data)
         if optimizer is not None:
+            logger.info(f"Setting optimizer type: {type(optimizer)}")
             megatron_lm_plugin.set_optimizer_type(optimizer)
         if scheduler is not None:
+            logger.info(f"Setting scheduler type: {type(scheduler)}")
             if not isinstance(scheduler, MegatronLMDummyScheduler):
                 raise ValueError(
                     "You can't use a custom scheduler with Megatron-LM. Please use the `accelerate.utils.MegatronLMDummyScheduler` instead."
diff --git a/src/accelerate/utils/dataclasses.py b/src/accelerate/utils/dataclasses.py
index bdc78bb..94c75fb 100644
--- a/src/accelerate/utils/dataclasses.py
+++ b/src/accelerate/utils/dataclasses.py
@@ -2537,7 +2537,7 @@ class MegatronLMPlugin:
     def set_network_size_args(self, model, batch_data=None):
         model_config_type = model.config.model_type.lower()
         for model_type in MODEL_CONFIGS_TO_MEGATRON_PARSERS.keys():
-            if model_type in model_config_type:
+            if model_type == model_config_type:
                 logger.info(f"Setting network size args for {model_type}")
                 MODEL_CONFIGS_TO_MEGATRON_PARSERS[model_type](self, model, batch_data)
                 return
@@ -2792,6 +2792,8 @@ def parse_qwen3_config(megatron_lm_plugin, model, batch_data):
     megatron_lm_plugin.megatron_lm_default_args["return_logits"] = megatron_lm_plugin.return_logits
     megatron_lm_plugin.megatron_lm_default_args["tokenizer_type"] = "Qwen3Tokenizer"
     megatron_lm_plugin.megatron_lm_default_args["model_type_name"] = model_type_name
+    megatron_lm_plugin.megatron_lm_default_args["eos_token_id"] = model.config.eos_token_id
+    megatron_lm_plugin.megatron_lm_default_args["original_model_type"] = model.config.model_type
     megatron_lm_plugin.megatron_lm_default_args["num_layers"] = num_layers
     megatron_lm_plugin.megatron_lm_default_args["pretraining_flag"] = pretraining_flag
     megatron_lm_plugin.megatron_lm_default_args["hidden_size"] = hidden_size
@@ -2854,6 +2856,52 @@ def parse_qwen3_moe_config(megatron_lm_plugin, model, batch_data):
     megatron_lm_plugin.megatron_lm_default_args["seq_length"] = megatron_lm_plugin.seq_length
     megatron_lm_plugin.megatron_lm_default_args["model_return_dict"] = model.config.return_dict
     megatron_lm_plugin.megatron_lm_default_args["position_embedding_type"] = 'rope'
+    megatron_lm_plugin.megatron_lm_default_args["original_model_type"] = model.config.model_type
+    megatron_lm_plugin.megatron_lm_default_args["qk_layernorm"] = True # model.config.use_qk_norm  # this is true for glm4.5 but False for glm4.5-air.
+    megatron_lm_plugin.megatron_lm_default_args["add_bias_linear"] = False
+    megatron_lm_plugin.megatron_lm_default_args["group_query_attention"] = True
+    megatron_lm_plugin.megatron_lm_default_args["num_query_groups"] = model.config.num_key_value_heads
+    megatron_lm_plugin.megatron_lm_default_args["ffn_hidden_size"] = model.config.intermediate_size
+    megatron_lm_plugin.megatron_lm_default_args["add_qkv_bias"] = False
+    megatron_lm_plugin.megatron_lm_default_args["normalization"] = 'RMSNorm'
+    megatron_lm_plugin.megatron_lm_default_args["rotary-percent"] = 1.0
+    megatron_lm_plugin.megatron_lm_default_args["swiglu"] = True
+    megatron_lm_plugin.megatron_lm_default_args["moe_ffn_hidden_size"] = model.config.moe_intermediate_size
+    # megatron_lm_plugin.megatron_lm_default_args["moe_shared_expert_intermediate_size"] = model.config.moe_intermediate_size
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_pre_softmax"] = False
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_score_function"] = "softmax"
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_enable_expert_bias"] = False
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_bias_update_rate"] = 0
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_load_balancing_type"] = "aux_loss"
+    megatron_lm_plugin.megatron_lm_default_args["moe_token_dispatcher_type"] = "alltoall"
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_bias_update_rate"] = 0.001
+    norm_epsilon = 1e-4
+    megatron_lm_plugin.megatron_lm_default_args["norm_epsilon"] = norm_epsilon
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_topk"] = model.config.num_experts_per_tok
+    # megatron_lm_plugin.megatron_lm_default_args["moe_router_topk_scaling_factor"] = model.config.router_aux_loss_coef
+    # megatron_lm_plugin.megatron_lm_default_args["moe_layer_freq"] = [0] * model.config.first_k_dense_replace + [1] * (model.config.num_hidden_layers - model.config.first_k_dense_replace)
+    megatron_lm_plugin.megatron_lm_default_args["num_experts"] = model.config.num_experts
+    megatron_lm_plugin.megatron_lm_default_args["moe_grouped_gemm"] = True
+    megatron_lm_plugin.megatron_lm_default_args["moe_router_dtype"] = "fp32"
+    megatron_lm_plugin.megatron_lm_default_args["moe_permute_fusion"] = True
+    megatron_lm_plugin.megatron_lm_default_args["moe_aux_loss_coeff"] = 0
+    megatron_lm_plugin.megatron_lm_default_args["rotary_base"] = model.config.rope_theta
+    megatron_lm_plugin.megatron_lm_default_args["rope_type"] = 'rope'
+    megatron_lm_plugin.megatron_lm_default_args["rotary_percent"] = 1.0 # model.config.partial_rotary_factor
+    megatron_lm_plugin.megatron_lm_default_args["decoder_last_pipeline_num_layers"] = 3
+    megatron_lm_plugin.megatron_lm_default_args["context_parallel_size"] = model.config.context_parallel_size
+    megatron_lm_plugin.megatron_lm_default_args["initial_loss_scale"] = 2**5
+    megatron_lm_plugin.megatron_lm_default_args["loss_scale"] = 2**5
+    megatron_lm_plugin.megatron_lm_default_args["use_flash_attn"] = True
+    megatron_lm_plugin.megatron_lm_default_args["eos_token_id"] = model.config.eos_token_id
+    # megatron_lm_plugin.megatron_lm_default_args["sequence_parallel"] = False
+    if model.config.fp8_param:
+        megatron_lm_plugin.megatron_lm_default_args["fp8"] = model.config.fp8
+        megatron_lm_plugin.megatron_lm_default_args["fp8_param"] = model.config.fp8_param
+        megatron_lm_plugin.megatron_lm_default_args["fp8_param_gather"] = model.config.fp8_param_gather
+        megatron_lm_plugin.megatron_lm_default_args["fp8_recipe"] = model.config.fp8_recipe
+    megatron_lm_plugin.megatron_lm_default_args["bf16"] = model.config.bf16
+    megatron_lm_plugin.megatron_lm_default_args["untie_embeddings_and_output_weights"] = not model.config.tie_word_embeddings  
     logger.info(f"Parsed Qwen3 MoE config: {megatron_lm_plugin.megatron_lm_default_args}")
 
 @add_model_config_to_megatron_parser("glm4_moe")
@@ -2890,7 +2938,7 @@ def parse_glm4_moe_config(megatron_lm_plugin, model, batch_data):
     megatron_lm_plugin.megatron_lm_default_args["seq_length"] = megatron_lm_plugin.seq_length
     megatron_lm_plugin.megatron_lm_default_args["model_return_dict"] = model.config.return_dict
     megatron_lm_plugin.megatron_lm_default_args["position_embedding_type"] = 'rope'
-
+    megatron_lm_plugin.megatron_lm_default_args["original_model_type"] = model.config.model_type
     megatron_lm_plugin.megatron_lm_default_args["qk_layernorm"] = model.config.use_qk_norm  # this is true for glm4.5 but False for glm4.5-air.
     megatron_lm_plugin.megatron_lm_default_args["add_bias_linear"] = False
     megatron_lm_plugin.megatron_lm_default_args["group_query_attention"] = True
@@ -2919,11 +2967,18 @@ def parse_glm4_moe_config(megatron_lm_plugin, model, batch_data):
     megatron_lm_plugin.megatron_lm_default_args["rotary_base"] = model.config.rope_theta
     megatron_lm_plugin.megatron_lm_default_args["rope_type"] = 'rope'
     megatron_lm_plugin.megatron_lm_default_args["rotary_percent"] = model.config.partial_rotary_factor
-    megatron_lm_plugin.megatron_lm_default_args["decoder_last_pipeline_num_layers"] = 2
-    # megatron_lm_plugin.megatron_lm_default_args["fp8"] = model.config.fp8
-    # megatron_lm_plugin.megatron_lm_default_args["fp8_param"] = model.config.fp8_param
-    # megatron_lm_plugin.megatron_lm_default_args["fp8_param_gather"] = model.config.fp8_param_gather
-    # megatron_lm_plugin.megatron_lm_default_args["fp8_recipe"] = model.config.fp8_recipe
+    megatron_lm_plugin.megatron_lm_default_args["decoder_last_pipeline_num_layers"] = 4
+    megatron_lm_plugin.megatron_lm_default_args["context_parallel_size"] = model.config.context_parallel_size
+    # megatron_lm_plugin.megatron_lm_default_args["initial_loss_scale"] = 2**5
+    megatron_lm_plugin.megatron_lm_default_args["norm_epsilon"] = 1e-3
+    megatron_lm_plugin.megatron_lm_default_args["use_flash_attn"] = True
+    megatron_lm_plugin.megatron_lm_default_args["eos_token_id"] = model.config.eos_token_id
+    # megatron_lm_plugin.megatron_lm_default_args["sequence_parallel"] = False
+    if model.config.fp8_param:
+        megatron_lm_plugin.megatron_lm_default_args["fp8"] = model.config.fp8
+        megatron_lm_plugin.megatron_lm_default_args["fp8_param"] = model.config.fp8_param
+        megatron_lm_plugin.megatron_lm_default_args["fp8_param_gather"] = model.config.fp8_param_gather
+        megatron_lm_plugin.megatron_lm_default_args["fp8_recipe"] = model.config.fp8_recipe
     megatron_lm_plugin.megatron_lm_default_args["bf16"] = model.config.bf16
     megatron_lm_plugin.megatron_lm_default_args["untie_embeddings_and_output_weights"] = not model.config.tie_word_embeddings
     logger.info(f"Parsed GLM4 MoE config: {megatron_lm_plugin.megatron_lm_default_args}")
diff --git a/src/accelerate/utils/megatron_lm.py b/src/accelerate/utils/megatron_lm.py
index ecf0a1d..7414d16 100644
--- a/src/accelerate/utils/megatron_lm.py
+++ b/src/accelerate/utils/megatron_lm.py
@@ -85,6 +85,34 @@ if is_megatron_lm_available():
     )
     from megatron.training.gpt_builders import gpt_builder
 
+import torch
+
+def mask_target_turn_torch(input_ids: torch.Tensor, turn_ids: list, target_turn: int):
+    """
+    Args:
+        input_ids: LongTensor of shape (seq_len,)
+        turn_ids: list of int, tokens that separate turns
+        target_turn: int, the turn token whose following tokens we want to mask
+    Returns:
+        mask: ByteTensor (or BoolTensor) of shape (seq_len,) with 1 for masked tokens, 0 otherwise
+    """
+    batch_size, seq_len = input_ids.size()
+    mask = torch.zeros(batch_size, seq_len, dtype=torch.bool, device=input_ids.device)
+    for b in range(batch_size):
+        i = 0
+        j = 0
+        while i < seq_len:
+            if input_ids[b, i].item() == target_turn:
+                # Start masking after this token
+                with_target_turn = True
+                j = i + 1
+                while j < seq_len and input_ids[b, j].item() not in turn_ids:
+                    mask[b, j] = True
+                    j += 1
+                i = j  # skip to next turn
+            else:
+                i += 1
+    return mask
 
 # model utilities
 def model_provider_func(pre_process=True, post_process=True, add_encoder=True, add_decoder=True):
@@ -95,9 +123,9 @@ def model_provider_func(pre_process=True, post_process=True, add_encoder=True, a
     args.recompute_num_layers = 1
     # args.use_torch_fsdp2 = True
     args.use_custom_fsdp = True
-    args.sequence_parallel = True
+    args.sequence_parallel = False
     args.attention_backend = True
-    args.expert_model_parallel_size = 1
+    args.expert_model_parallel_size = 4
     # args.data_parallel_sharding_strategy = "optim_grads_params"
     mode = "pre-training" if args.pretraining_flag else "fine-tuning"
     logging.info(f"in model_provider_func with args: {args}")
@@ -608,13 +636,18 @@ class GPTTrainStep(AbstractTrainStep):
         self.get_batch = self.get_batch_func(accelerator, args.megatron_dataset_flag)
         self.loss_func = self.get_loss_func(accelerator)
         self.forward_step = self.get_forward_step_func()
-        self.eod_token = args.padded_vocab_size - 1
+        # self.eod_token = args.padded_vocab_size - 1
         if args.vocab_file is not None:
             tokenizer = get_tokenizer()
             self.eod_token = tokenizer.eod
+        self.eod_token = args.eos_token_id
+        self.pad_token = args.eos_token_id
         self.reset_position_ids = args.reset_position_ids
         self.reset_attention_mask = args.reset_attention_mask
         self.eod_mask_loss = args.eod_mask_loss
+        if args.original_model_type == "glm4_moe":
+            self.turn_ids = [151335, 151336,151337,151338]
+            self.target_turn = 151337
         if not args.model_return_dict:
             self.model_output_class = None
         else:
@@ -645,7 +678,14 @@ class GPTTrainStep(AbstractTrainStep):
             attention_mask, loss_mask, position_ids = get_ltor_masks_and_position_ids(
                 tokens, eod_token=self.eod_token, pad_token=self.eod_token, reset_position_ids=self.reset_position_ids, reset_attention_mask=self.reset_attention_mask, eod_mask_loss=self.eod_mask_loss, pad_mask_loss=True,
             )
-
+            # print(f"I am in get_batch_megatron, labels: {labels}, tokens: {tokens}, loss_mask: {loss_mask}, attention_mask: {attention_mask}, position_ids: {position_ids}")
+            if self.turn_ids is not None and self.target_turn is not None:
+                logging.info(f"I am in get_batch_megatron, tokens: {tokens}, turn_ids: {self.turn_ids}, target_turn: {self.target_turn}")
+                turn_mask = mask_target_turn_torch(tokens, self.turn_ids, self.target_turn)
+                loss_mask = loss_mask * turn_mask
+                if torch.sum(loss_mask) == 0:
+                    logging.info(f"I am in get_batch_megatron, loss_mask is all zeros, meaning that this data doesn't contain the assistant's turn, this could be due to the data is not properly formatted or the sequence is too short, we will skip this data")
+                # assert torch.sum(loss_mask) > 0, f"I am in get_batch_megatron, loss_mask: {loss_mask}, turn_mask: {turn_mask}"
             return tokens, labels, loss_mask, attention_mask, position_ids
 
         def get_batch_transformer(data_iterator):
@@ -662,6 +702,14 @@ class GPTTrainStep(AbstractTrainStep):
             attention_mask, loss_mask, position_ids = get_ltor_masks_and_position_ids(
                 tokens, eod_token=self.eod_token, pad_token=self.eod_token, reset_position_ids=self.reset_position_ids, reset_attention_mask=self.reset_attention_mask, eod_mask_loss=self.eod_mask_loss, pad_mask_loss=True,
             )
+            # print(f"I am in get_batch_transformer, labels: {labels}, tokens: {tokens}, loss_mask: {loss_mask}, attention_mask: {attention_mask}, position_ids: {position_ids}")
+            if self.turn_ids is not None and self.target_turn is not None:
+                # logging.info(f"I am in get_batch_transformer, tokens: {tokens}, turn_ids: {self.turn_ids}, target_turn: {self.target_turn}")
+                turn_mask = mask_target_turn_torch(tokens, self.turn_ids, self.target_turn)
+                loss_mask = loss_mask * turn_mask
+                if torch.sum(loss_mask) == 0:
+                    logging.info(f"I am in get_batch_transformer, loss_mask is all zeros, meaning that this data doesn't contain the assistant's turn, this could be due to the data is not properly formatted or the sequence is too short, we will skip this data")
+                # assert torch.sum(loss_mask) > 0, f"I am in get_batch_transformer, loss_mask: {loss_mask}, turn_mask: {turn_mask}"
             return tokens, labels, loss_mask, attention_mask, position_ids
 
         if accelerator.state.megatron_lm_plugin.custom_get_batch_function is not None:
@@ -689,10 +737,12 @@ class GPTTrainStep(AbstractTrainStep):
             losses = losses.float()
             loss_mask = loss_mask.view(-1).float()
             if args.context_parallel_size > 1:
+                logging.info(f"in context_parallel_size > 1, loss value {torch.sum(losses.view(-1))} and loss_mask.sum(): {loss_mask.sum()}")
                 loss = torch.cat([torch.sum(losses.view(-1) * loss_mask).view(1), loss_mask.sum().view(1)])
                 torch.distributed.all_reduce(loss, group=mpu.get_context_parallel_group())
                 loss = loss[0] / loss[1]
             else:
+                # print(f"in context_parallel_size == 1, loss value {torch.sum(losses.view(-1))} and loss_mask.sum(): {loss_mask.sum()}")
                 loss = torch.sum(losses.view(-1) * loss_mask) / loss_mask.sum()
 
             # Check individual rank losses are not NaN prior to DP all-reduce.
@@ -722,6 +772,8 @@ class GPTTrainStep(AbstractTrainStep):
             tokens, labels, loss_mask, attention_mask, position_ids = self.get_batch(data_iterator)
             output_tensor = model(tokens, position_ids, attention_mask, labels=labels)
 
+            # logging.info(f"gpt forward_step 729: output_tensor: {output_tensor.shape}, if has nan: {torch.isnan(output_tensor).any()}")
+            # logging.info(f"gpt forward_step 731: output_tensor: {output_tensor.shape}, if has nan: {torch.isnan(output_tensor).any()}")
             return output_tensor, partial(self.loss_func, loss_mask)
 
         return forward_step
@@ -958,6 +1010,8 @@ class MegatronEngine(torch.nn.Module):
         elif args.model_type_name == "bert":
             self.train_step_handler = BertTrainStep(accelerator, args)
         elif args.model_type_name == "gpt":
+            # args.eos_token_id = model[0].config.eos_token_id[0]
+            print(f"I am in MegatronEngine, args.eos_token_id: {args.eos_token_id}")
             self.train_step_handler = GPTTrainStep(accelerator, args)
         elif args.model_type_name == "t5":
             self.train_step_handler = T5TrainStep(accelerator, args)
